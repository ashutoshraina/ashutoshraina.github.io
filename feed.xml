<rss xmlns:a10="http://www.w3.org/2005/Atom" version="2.0"><channel><title /><link>http://ashutoshraina.github.io/feed.xml</link><description /><item><guid isPermaLink="true">http://ashutoshraina.github.io/2014/01/optimistic-concurrency-mongodb/</guid><link>http://ashutoshraina.github.io/2014/01/optimistic-concurrency-mongodb/</link><title>MongoDb: Optimistic Concurrency</title><description>&lt;p&gt;Optimistic concurrency is one something that most of us need in our applications. What follows is a simple example on how to achieve it in MongoDB.
First, a really simple document.&lt;/p&gt;

&lt;p&gt;Note : This post uses a lot of code that I have shown in previous posts, please look at them if there is any confusion. The principles remain simple and can be used without using the code shown below.&lt;/p&gt;

</description><pubDate>Fri, 17 Jan 2014 18:30:00 Z</pubDate><a10:updated>2014-01-17T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;Optimistic concurrency is one something that most of us need in our applications. What follows is a simple example on how to achieve it in MongoDB.
First, a really simple document.&lt;/p&gt;

&lt;p&gt;Note : This post uses a lot of code that I have shown in previous posts, please look at them if there is any confusion. The principles remain simple and can be used without using the code shown below.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;pre&gt;&lt;code&gt;public class Person : MongoEntity {
        public string Name { get; set; }
        public long Version { get ; set ; }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, when you want to edit a person it becomes a simple FindAndModify.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public bool EditPerson (Person person) {
            //find the document with thr same id and version
            var query = Query.And(
                Query&amp;lt;Person&amp;gt;.EQ(_ =&amp;gt; _.Version, person.Version), 
                Query&amp;lt;Person&amp;gt;.EQ(_ =&amp;gt; _.Id, person.Id));

            //bump the version

            var updatedPerson = person;
            updatedPerson.Version = person.Version + 1;
            var result = PersonConnectionHandler.MongoCollection.FindAndModify(query, null, 
                Update.Replace&amp;lt;Person&amp;gt;(updatedPerson), true);

            if ( result.ModifiedDocument != null ) {
                Console.WriteLine("Document Modified successfully");
                Console.WriteLine(result.ModifiedDocument);
                return true;
            } else {
                return false;
            }
        }
&lt;/code&gt;&lt;/pre&gt;
</a10:content></item><item><guid isPermaLink="true">http://ashutoshraina.github.io/2014/01/querying-oplog-mongodb/</guid><link>http://ashutoshraina.github.io/2014/01/querying-oplog-mongodb/</link><title>MongoDb: Querying the OpLog</title><description>&lt;p&gt;Back to MongoDB after some time. OpLog has always been a curious case for me. To know more about it let's start to our detective work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is the OpLog?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The mongodb website gives a rather long definition. I will quote that &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The oplog (operations log) is a special capped collection that keeps a rolling record of all operations that modify the data stored in your databases. MongoDB applies database operations on the primary and then records the operations on the primary’s oplog. The secondary members then copy and apply these operations in an asynchronous process. All replica set members contain a copy of the oplog, allowing them to maintain the current state of the database.&lt;/p&gt;
  
  &lt;p&gt;To facilitate replication, all replica set members send heartbeats (pings) to all other members. Any member can import oplog entries from any other member.
  Whether applied once or multiple times to the target dataset, each operation in the oplog produces the same results, i.e. each operation in the oplog is idempotent. For proper replication operations, entries in the oplog must be idempotent:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;initial sync&lt;/li&gt;
&lt;li&gt;post-rollback catch-up&lt;/li&gt;
&lt;li&gt;sharding chunk migrations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;</description><pubDate>Thu, 09 Jan 2014 18:30:00 Z</pubDate><a10:updated>2014-01-09T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;Back to MongoDB after some time. OpLog has always been a curious case for me. To know more about it let's start to our detective work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is the OpLog?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The mongodb website gives a rather long definition. I will quote that &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The oplog (operations log) is a special capped collection that keeps a rolling record of all operations that modify the data stored in your databases. MongoDB applies database operations on the primary and then records the operations on the primary’s oplog. The secondary members then copy and apply these operations in an asynchronous process. All replica set members contain a copy of the oplog, allowing them to maintain the current state of the database.&lt;/p&gt;
  
  &lt;p&gt;To facilitate replication, all replica set members send heartbeats (pings) to all other members. Any member can import oplog entries from any other member.
  Whether applied once or multiple times to the target dataset, each operation in the oplog produces the same results, i.e. each operation in the oplog is idempotent. For proper replication operations, entries in the oplog must be idempotent:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;initial sync&lt;/li&gt;
&lt;li&gt;post-rollback catch-up&lt;/li&gt;
&lt;li&gt;sharding chunk migrations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;!--excerpt--&gt;
So, the oplog is applicable for a replica set but then do I really need a non-trivial process to start playing with it ? And to your heart's delight the answer is no.
Oplog is not turned on by default when you have a single node in your cluster (of course, who would want that to be way (read me)). OK, let's create a one node replica set then.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    mongod.exe --replSet myreplSet --oplogSize 50
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now have a one node repl set with the oplog of 50mb. One liners are always cool !!&lt;/p&gt;

&lt;p&gt;Let's go on our querying streak. Start the monog.exe and let's go to the local database and find our oplog.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rs0:PRIMARY&amp;gt; use local
switched to db local
rs0:PRIMARY&amp;gt; show collections
oplog.rs
startup_log
system.replset
rs0:PRIMARY&amp;gt; db.oplog.rs.findOne();
{
        "ts" : {
                "t" : 1387363823,
                "i" : 1
        },
        "h" : NumberLong(0),
        "v" : 2,
        "op" : "n",
        "ns" : "",
        "o" : {
                "msg" : "initiating set"
        }
}
rs0:PRIMARY&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We just don't want to query it simply we really do want to get it into our application in real-time. Let's move to the application code now.&lt;/p&gt;

&lt;p&gt;Now, If you look at my previous posts you will recollect that we had a generic version of MongoConnectionHandler. For querying the oplog, I created a non-generic one for this since it makes our lives just a touch easier by not asking us to derive from an IMongoEntity.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class MongoConnectionHandler
    {
        public MongoCollection MongoCollection { get; private set; }
        private const string ConnectionString = @"mongodb://localhost";
        public MongoConnectionHandler(string databaseName, string collection)
        {
            var client = new MongoClient(ConnectionString);
            var server = client.GetServer();
            var database = server.GetDatabase(databaseName);
            MongoCollection = database.GetCollection(collection);
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, we can query the oplog quite simply by switching to the local daatbase and reading the &lt;strong&gt;&lt;em&gt;BsonDocument&lt;/em&gt;&lt;/strong&gt; that is returned.&lt;/p&gt;

&lt;p&gt;Note: The orignial version was written in the examples in java and is available on Github as part of examples of the java driver.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class QueryOpLog {
        protected readonly MongoConnectionHandler OpLogHandler;
        public QueryOpLog () {
            OpLogHandler = new MongoConnectionHandler("local", "oplog.rs");
        }
        public IEnumerable&amp;lt;BsonDocument&amp;gt; GetLastEntryInOpLog () {           
            BsonValue lastId = BsonMinKey.Value;
            while (true) {
                var query = Query.GT("ts", lastId);
                var cursor = OpLogHandler.MongoCollection.FindAs&amp;lt;BsonDocument&amp;gt;(query)
                            .SetFlags(QueryFlags.TailableCursor | QueryFlags.AwaitData)
                            .SetSortOrder(SortBy.Ascending("$natural"));
                var count = 0;
                foreach (var document in cursor) {
                    lastId = document["ts"];
                    Console.WriteLine("LastId is {0}", lastId);
                    yield return document;
                    count++;
                }
                if ( count == 0 ) {
                    Thread.Sleep(TimeSpan.FromMilliseconds(100));
                }
            }           
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are a few things going on here. One, some flags are being set in the query to get a tailable cursor and we are basically querying the oplog only if we have a new document by using a count. &lt;strong&gt;&lt;em&gt;yield&lt;/em&gt;&lt;/strong&gt; makes for a nicer syntax for the consumer of this method.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var oplog = new QueryOpLog();
var resut = oplog.GetLastEntryInOpLog();
resut.ForEach(r =&amp;gt; Console.WriteLine(r));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, go on and make some operations through the shell and watch the oplog show up in a console window.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://ashutoshraina.github.io/2014/01/mvc-on-mono-monodevelop/</guid><link>http://ashutoshraina.github.io/2014/01/mvc-on-mono-monodevelop/</link><title>Up and Running with Asp.net MVC Mono and Monodevelop</title><description>&lt;p&gt;After 3 hours worth of work, I was finally able to run Asp.net MVC4 using monodevelop on mono. I will talk about installaing monodevelop later (that was a painful exercise). So, assuming you have monodevelop installed on windows and latest version of mono installed (mono-3.2.3)as well. Now, go file new solution Asp.net MVC project with razor. Run it and wait for the world to fall apart.&lt;/p&gt;

</description><pubDate>Thu, 02 Jan 2014 18:30:00 Z</pubDate><a10:updated>2014-01-02T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;After 3 hours worth of work, I was finally able to run Asp.net MVC4 using monodevelop on mono. I will talk about installaing monodevelop later (that was a painful exercise). So, assuming you have monodevelop installed on windows and latest version of mono installed (mono-3.2.3)as well. Now, go file new solution Asp.net MVC project with razor. Run it and wait for the world to fall apart.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;&lt;img src="http://ashutoshraina.github.io/stylesheets/images/posts/mono-mvc-error.png" alt="Mono MVC Error" /&gt;&lt;/p&gt;

&lt;p&gt;Now, here is the long recipe of fixing it one step at a time. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Go to Project Options -&amp;gt; General -&amp;gt; Change the Target Framework to Mono/.net4.5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install the Asp.net MVC Nuget package.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://ashutoshraina.github.io/stylesheets/images/posts/nuget-install.png" alt="Nuget Install" /&gt;&lt;/p&gt;

&lt;p&gt;Now, compile and go yayy!!
Press F5 and wait for your happiness to go away.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"Could not launch web server. Make sure that XSP4 web server is installed".
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Don't worry it is installed the mono guys just wanted to have fun by poking us with a stick. Copy the &lt;strong&gt;winhack&lt;/strong&gt; folder from &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Program Files (x86)\Mono-3.2.3\lib\mono\4.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;C:\Program Files (x86)\Mono-3.2.3\lib\mono\4.5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I was only able to arrive at this hack by looking at the monosoftdebugger source code and a bit of hit and miss. In between I asked around if there was a way to attache IIS Express to monodevelop, I couldn't find anything that was simple and obvious (ended up with a useful IISExpress manager utility, more on that later). If you change the target framework to .net 4 and monitor the application output tab then you will the following and it will make sense as to how I reached winhack folder.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Loaded assembly: C:\Program Files (x86)\Mono-3.2.3\lib\mono\4.5\winhack\xsp4.exe
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, press F5 again and the misery continues, but thankfully this is something we understand.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.InvalidOperationException
Conflicting versions of ASP.NET Web Pages detected: specified version is "1.0.0.0", but the version in bin is "3.0.0.0". To continue, remove files from the application's bin directory or remove the version specification in web.config.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In project's web.config change the version.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;add key="webpages:Version" value="3.0.0.0" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let's press F5 again.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;System.InvalidOperationException
Could not locate Razor Host Factory type: System.Web.Mvc.MvcWebRazorHostFactory, System.Web.Mvc, Version=3.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the web.config located in the views folder change the version to the appropriate mvc version.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;host factoryType="System.Web.Mvc.MvcWebRazorHostFactory, System.Web.Mvc, Version=5.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Side Note : Better, change the version wherever it needs to be updated.&lt;/p&gt;

&lt;p&gt;Now, Press F5.&lt;/p&gt;

&lt;p&gt;&lt;img src="http://ashutoshraina.github.io/stylesheets/images/posts/mvc-mono-success.png" alt="Success" /&gt;&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://ashutoshraina.github.io/2013/12/tasks-with-timeout-net4.5-contd/</guid><link>http://ashutoshraina.github.io/2013/12/tasks-with-timeout-net4.5-contd/</link><title>Tasks With Timeout On .net 4.5 Contd.</title><description>&lt;p&gt;The previous two posts looked at creating tasks with timeouts on .net4. The code as expected took some heavy lifting to get going. Understanding the extension methods themselves took some time. Today, using .net 4.5 this can be made a lot easier. Can we do better ? Yes we can !!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    public static Task WithTimeout(this Task task, TimeSpan timeout)
    {
        var delay = task.ContinueWith(t =&amp;gt; { }, new CancellationTokenSource(timeout).Token);
        return Task.WhenAny(task, delay).Unwrap();
    }
    public static Task&amp;lt;T&amp;gt; WithTimeout&amp;lt;T&amp;gt;(this Task&amp;lt;T&amp;gt; task, TimeSpan timeout)
    {            
        var delay = task.ContinueWith(t =&amp;gt; t.Result, new CancellationTokenSource(timeout).Token);
        return Task.WhenAny(task, delay).Unwrap();
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;</description><pubDate>Sun, 29 Dec 2013 18:30:00 Z</pubDate><a10:updated>2013-12-29T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;The previous two posts looked at creating tasks with timeouts on .net4. The code as expected took some heavy lifting to get going. Understanding the extension methods themselves took some time. Today, using .net 4.5 this can be made a lot easier. Can we do better ? Yes we can !!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    public static Task WithTimeout(this Task task, TimeSpan timeout)
    {
        var delay = task.ContinueWith(t =&amp;gt; { }, new CancellationTokenSource(timeout).Token);
        return Task.WhenAny(task, delay).Unwrap();
    }
    public static Task&amp;lt;T&amp;gt; WithTimeout&amp;lt;T&amp;gt;(this Task&amp;lt;T&amp;gt; task, TimeSpan timeout)
    {            
        var delay = task.ContinueWith(t =&amp;gt; t.Result, new CancellationTokenSource(timeout).Token);
        return Task.WhenAny(task, delay).Unwrap();
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;!--excerpt--&gt;
OK, so that really trimmed the code. Usage still remains the same with one difference. The task will now be really cancelled and not faulted which will force us to change the TaskContinuationOptions to NotOnCanceled.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Program
{
    private static List&amp;lt;int&amp;gt; Output = new List&amp;lt;int&amp;gt;();
    private static Random _random = new Random();

    public static int LongRunningTask(string message)
    {
        Console.WriteLine(message);
        Console.WriteLine("Managed thread Id " + Thread.CurrentThread.ManagedThreadId);
        //Simulate a long running task
        Thread.Sleep(TimeSpan.FromSeconds(2));
        var number = _random.Next();
        Console.WriteLine("Adding " + number + " From thread  - " + Thread.CurrentThread.ManagedThreadId);
        return number;
    }
    public static void Main(string[] args)
    {
        Console.WriteLine("In Main");
        TimeoutonNet45();
        Console.ReadLine();
    }

    public static void TimeoutonNet45()
    {
        Console.WriteLine("Managed thread Id " + Thread.CurrentThread.ManagedThreadId);
        var tasks = new List&amp;lt;Task&amp;gt;();
        try
        {
            var t1 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task1"),TaskCreationOptions.AttachedToParent)
                                 .WithTimeout(TimeSpan.FromMilliseconds(1000))                
                                 .ContinueWith(t =&amp;gt; Output.Add(t.Result), TaskContinuationOptions.NotOnCanceled);
            var t2 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task2"), TaskCreationOptions.AttachedToParent)
                                 .ContinueWith(_ =&amp;gt; Output.Add(_.Result));
            tasks.Add(t1);
            tasks.Add(t2);
            Task.WaitAll(tasks.ToArray());
        }
        catch (Exception ex)
        {
            Console.WriteLine("There was an exception");
            Console.WriteLine(ex.InnerException.Message);
        }
        Console.WriteLine("Output :");
        Output.ForEach(_ =&amp;gt; Console.WriteLine(_));
    }

    public static void TimeoutOnNet4()
    {
        Console.WriteLine("Managed thread Id " + Thread.CurrentThread.ManagedThreadId);
        var tasks = new List&amp;lt;Task&amp;gt;();
        try
        {
            var t1 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task1"), TaskCreationOptions.AttachedToParent)
                                 .TimeoutAfter(1000)
                                 .ContinueWith(t =&amp;gt; Output.Add(t.Result), TaskContinuationOptions.NotOnFaulted);
            var t2 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task2"), TaskCreationOptions.AttachedToParent)
                                 .ContinueWith(_ =&amp;gt; Output.Add(_.Result));
            var t3 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task3"), TaskCreationOptions.AttachedToParent)
                                 .ContinueWith(_ =&amp;gt; Output.Add(_.Result));
            tasks.Add(t1);
            tasks.Add(t2);
            tasks.Add(t3);
            Task.WaitAll(tasks.ToArray());
        }
        catch (Exception ex)
        {
            Console.WriteLine("There was an exception");
            Console.WriteLine(ex.InnerException.Message);
        }
        Console.WriteLine("Output :");
        Output.ForEach(_ =&amp;gt; Console.WriteLine(_));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The output will look something like this :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;In Main
Managed thread Id 10
Entering task1
Managed thread Id 11
Entering task2
Managed thread Id 12
Adding 856463453 From thread  - 12
Adding 1826416296 From thread  - 11
There was an exception
A task was canceled.
Output :
856463453
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A more robust means will always be to check for both faults and cancellation within the continuation. So, this makes creating tasks with timouts a lot easier.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://ashutoshraina.github.io/2013/12/tasks-with-timeout-contd/</guid><link>http://ashutoshraina.github.io/2013/12/tasks-with-timeout-contd/</link><title>Tasks With Timeout Contd.</title><description>&lt;p&gt;As mentioned in the last post we can now have tasks with individual timeouts. The code looked a little heavy. Can we do better ? Yes we can !!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    var tasks = new List&amp;lt;Task&amp;gt;();
    try
    {
    //instead of checking for fault within the continutaion, 
    //we can just use a TaskContinuationOption to tell communicate the right semantics

    var t1 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask(),TaskCreationOptions.AttachedToParent)
    .TimeoutAfter(1000)
    .ContinueWith(t =&amp;gt; SomethingUsefulWithTheResult(), 
     TaskContinuationOptions.NotOnFaulted);

    var t2 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask(), TaskCreationOptions.AttachedToParent)
      .ContinueWith(t =&amp;gt; SomethingUsefulWithTheResult());

    var t3 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task3"),
    TaskCreationOptions.AttachedToParent)
      .ContinueWith(t =&amp;gt; SomethingUsefulWithTheResult());

    tasks.Add(t1);
    tasks.Add(t2);
    tasks.Add(t3);

    Task.WaitAll(tasks.ToArray());
    }
    catch (Exception ex)
    {
    Console.WriteLine("There was an exception");
    Console.WriteLine(ex.InnerException.Message);   
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I will show in the next post how this wasn't all that better since this leaves a few gaps.&lt;/p&gt;
</description><pubDate>Mon, 23 Dec 2013 18:30:00 Z</pubDate><a10:updated>2013-12-23T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;As mentioned in the last post we can now have tasks with individual timeouts. The code looked a little heavy. Can we do better ? Yes we can !!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    var tasks = new List&amp;lt;Task&amp;gt;();
    try
    {
    //instead of checking for fault within the continutaion, 
    //we can just use a TaskContinuationOption to tell communicate the right semantics

    var t1 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask(),TaskCreationOptions.AttachedToParent)
    .TimeoutAfter(1000)
    .ContinueWith(t =&amp;gt; SomethingUsefulWithTheResult(), 
     TaskContinuationOptions.NotOnFaulted);

    var t2 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask(), TaskCreationOptions.AttachedToParent)
      .ContinueWith(t =&amp;gt; SomethingUsefulWithTheResult());

    var t3 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task3"),
    TaskCreationOptions.AttachedToParent)
      .ContinueWith(t =&amp;gt; SomethingUsefulWithTheResult());

    tasks.Add(t1);
    tasks.Add(t2);
    tasks.Add(t3);

    Task.WaitAll(tasks.ToArray());
    }
    catch (Exception ex)
    {
    Console.WriteLine("There was an exception");
    Console.WriteLine(ex.InnerException.Message);   
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I will show in the next post how this wasn't all that better since this leaves a few gaps.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://ashutoshraina.github.io/2013/12/tasks-with-timeouts/</guid><link>http://ashutoshraina.github.io/2013/12/tasks-with-timeouts/</link><title>Tasks With Timeout</title><description>&lt;p&gt;So the task is to timeout a task. now, I never thought it would take me as long as it did. Turns out it is a really tricky problem problem. I was expecting something within the framework to make life easier, there isn't anything by default but msdn to the rescue 
&lt;a href="http://blogs.msdn.com/b/pfxteam/archive/2011/11/10/10235834.aspx" title="Tasks With Timeout"&gt;Tasks With Timeouts&lt;/a&gt;&lt;/p&gt;

</description><pubDate>Sun, 22 Dec 2013 18:30:00 Z</pubDate><a10:updated>2013-12-22T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;So the task is to timeout a task. now, I never thought it would take me as long as it did. Turns out it is a really tricky problem problem. I was expecting something within the framework to make life easier, there isn't anything by default but msdn to the rescue 
&lt;a href="http://blogs.msdn.com/b/pfxteam/archive/2011/11/10/10235834.aspx" title="Tasks With Timeout"&gt;Tasks With Timeouts&lt;/a&gt;&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;So, the extension method is &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static class TaskWithTimeout
{
    internal struct VoidTypeStruct
    { }
    internal static void MarshalTaskResults&amp;lt;TResult&amp;gt;(Task source, TaskCompletionSource&amp;lt;TResult&amp;gt; proxy)
    {
        switch (source.Status)
        {
            case TaskStatus.Faulted:
                proxy.TrySetException(source.Exception);
                break;
            case TaskStatus.Canceled:
                proxy.TrySetCanceled();
                break;
            case TaskStatus.RanToCompletion:
                Task&amp;lt;TResult&amp;gt; castedSource = source as Task&amp;lt;TResult&amp;gt;;
                proxy.TrySetResult(
                    castedSource == null ? default(TResult) : // source is a Task
                        castedSource.Result); // source is a Task&amp;lt;TResult&amp;gt;
                break;
        }
    }

    public static Task TimeoutAfter(this Task task, int millisecondsTimeout)
    {
        // Short-circuit #1: infinite timeout or task already completed
        if (task.IsCompleted || (millisecondsTimeout == Timeout.Infinite))
        {
            // Either the task has already completed or timeout will never occur.
            // No proxy necessary.
            return task;
        }

        // tcs.Task will be returned as a proxy to the caller
        TaskCompletionSource&amp;lt;VoidTypeStruct&amp;gt; tcs = new TaskCompletionSource&amp;lt;VoidTypeStruct&amp;gt;();

        // Short-circuit #2: zero timeout
        if (millisecondsTimeout == 0)
        {
            // We've already timed out.
            tcs.SetException(new TimeoutException());
            return tcs.Task;
        }

        // Set up a timer to complete after the specified timeout period
        Timer timer = new Timer(state =&amp;gt;
        {
            // Recover your state information
            var myTcs = (TaskCompletionSource&amp;lt;VoidTypeStruct&amp;gt;)state;
            // Fault our proxy with a TimeoutException
            myTcs.TrySetException(new TimeoutException());
        }, tcs, millisecondsTimeout, Timeout.Infinite);

        // Wire up the logic for what happens when source task completes
        task.ContinueWith(antecedent =&amp;gt;
                            {
                                timer.Dispose(); // Cancel the timer
                                MarshalTaskResults(antecedent, tcs); // Marshal results to proxy
                            },
                            CancellationToken.None, TaskContinuationOptions.ExecuteSynchronously, TaskScheduler.Default);

        return tcs.Task;
    }

    public static Task&amp;lt;TResult&amp;gt; TimeoutAfter&amp;lt;TResult&amp;gt;(this Task&amp;lt;TResult&amp;gt; task, int millisecondsTimeout)
    {
        // Short-circuit #1: infinite timeout or task already completed
        if (task.IsCompleted || (millisecondsTimeout == Timeout.Infinite))
        {
            // Either the task has already completed or timeout will never occur.
            // No proxy necessary.
            return task;
        }

        // tcs.Task will be returned as a proxy to the caller
        TaskCompletionSource&amp;lt;TResult&amp;gt; tcs = new TaskCompletionSource&amp;lt;TResult&amp;gt;();

        // Short-circuit #2: zero timeout
        if (millisecondsTimeout == 0)
        {
            // We've already timed out.
            tcs.SetException(new TimeoutException());
            return tcs.Task;
        }

        // Set up a timer to complete after the specified timeout period
        Timer timer = new Timer(state =&amp;gt;
                                {
                                    // Recover your state information
                                    var myTcs = (TaskCompletionSource&amp;lt;TResult&amp;gt;)state;
                                    // Fault our proxy with a TimeoutException
                                    myTcs.TrySetException(new TimeoutException());
                                }, tcs, millisecondsTimeout, Timeout.Infinite);

        // Wire up the logic for what happens when source task completes
        task.ContinueWith(antecedent =&amp;gt;
                            {
                                timer.Dispose(); // Cancel the timer
                                MarshalTaskResults(antecedent, tcs); // Marshal results to proxy
                            }, 
                            CancellationToken.None, TaskContinuationOptions.ExecuteSynchronously,TaskScheduler.Default);

        return tcs.Task;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A lot of code for doing this, and the msdn article remains the better source of explanation.&lt;/p&gt;

&lt;p&gt;Now using this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Program
    {
        private static List&amp;lt;int&amp;gt; Output = new List&amp;lt;int&amp;gt;();
        private static Random _random = new Random();

        public static int LongRunningTask(string message)
        {
            Console.WriteLine(message);
            Console.WriteLine("Managed thread Id " + Thread.CurrentThread.ManagedThreadId);
            //Simulate a long running task
            Thread.Sleep(TimeSpan.FromSeconds(2));
            var number = _random.Next();
            Console.WriteLine("Adding " + number + " From thread  - " + Thread.CurrentThread.ManagedThreadId);
            return number;
        }

        public static void Main(string[] args)
        {
            Console.WriteLine("In Main");
            Console.WriteLine("Managed thread Id " + Thread.CurrentThread.ManagedThreadId);
            var cts = new CancellationTokenSource();
            var tasks = new List&amp;lt;Task&amp;gt;();
            try
            {
//In the continuation check for the condition of fault (or something more if you so need) and perform the //continuation
                var t1 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task1"),
                                                    TaskCreationOptions.AttachedToParent)
                                     .TimeoutAfter(1000)
                                     .ContinueWith(antecedent =&amp;gt; {
                        if(!(antecedent.IsCanceled || antecedent.IsFaulted))
                                                         Output.Add(antecedent.Result);
                                }
                                , cts.Token);
                var t2 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task2"),
                                                    TaskCreationOptions.AttachedToParent)
                                     .ContinueWith(_ =&amp;gt; Output.Add(_.Result));
                var t3 = Task.Factory.StartNew(_ =&amp;gt; LongRunningTask("Entering task3"), 
                                                    TaskCreationOptions.AttachedToParent)
                                     .ContinueWith(_ =&amp;gt; Output.Add(_.Result));

                tasks.Add(t1);
                tasks.Add(t2);
                tasks.Add(t3);

                Task.WaitAll(tasks.ToArray());
            }
            catch (Exception ex)
            {                
                Console.WriteLine("There was an exception");
                Console.WriteLine(ex.InnerException.Message);               
            }

            Console.WriteLine("Output :");
            Output.ForEach(_ =&amp;gt; Console.WriteLine(_));

            Console.ReadLine();
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The important part being that the continuation is applied after the timeout and it won't work with the other way around.
The output therefore basically looks like this : &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;In Main
Managed thread Id 9
Entering task1
Managed thread Id 10
Entering task2
Managed thread Id 11
Entering task3
Managed thread Id 14
Adding 194443354 From thread  - 10
Adding 792426557 From thread  - 11
Adding 230130793 From thread  - 14
Output :
792426557
230130793
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, time I will try and write about some other things on Flirting with Tasks.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://ashutoshraina.github.io/2013/11/mongodb-sharding/</guid><link>http://ashutoshraina.github.io/2013/11/mongodb-sharding/</link><title>MongoDB-Sharding</title><description>&lt;p&gt;&lt;strong&gt;Sharding&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Mongodb sharding is based on shard key.&lt;/p&gt;

&lt;p&gt;K1 -&amp;gt; k2 on shard1
K2 -&amp;gt; k3 on shard2 etc..&lt;/p&gt;

&lt;p&gt;Each shard is then replicated for higher availability and DR etc..Sharding is therefore range based. Sharding is done per collections basis.Range based sharding helps it do range based queries.&lt;/p&gt;

</description><pubDate>Mon, 04 Nov 2013 18:30:00 Z</pubDate><a10:updated>2013-11-04T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;&lt;strong&gt;Sharding&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Mongodb sharding is based on shard key.&lt;/p&gt;

&lt;p&gt;K1 -&amp;gt; k2 on shard1
K2 -&amp;gt; k3 on shard2 etc..&lt;/p&gt;

&lt;p&gt;Each shard is then replicated for higher availability and DR etc..Sharding is therefore range based. Sharding is done per collections basis.Range based sharding helps it do range based queries.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;All of the documents on a particular shard are known as chunks ~~ 100mb.&lt;/p&gt;

&lt;p&gt;There are two operations that happen in the background in sharding and these are done automatically for us.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Split - splits a range if the range is producing bigger chunks, this is fairly expensive&lt;/li&gt;
&lt;li&gt;Migrate - moves chunks to somewhere else in the cluster, this is somewhat expensive.
&lt;ul&gt;
&lt;li&gt;Between a pair of shards there will not be more than one migration activity.&lt;/li&gt;
&lt;li&gt;We can still read and write from the data when we are migrating. So, it is live.&lt;/li&gt;
&lt;li&gt;"Balancer" decides when to do the balancing. It balances on the number of chunks today.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Both of these are done to maintain a balance in the shards w.r.t. the documents.
The metadata about these shards and our system is stored in config servers. These are light weight.
Conceptually these shards are processes and not separate physical machines or virtual machines although they can and most likely will be.&lt;/p&gt;

&lt;p&gt;Mongos gives the client the big picture of the whole setup. Client is therefore insulated from the underlying architecture that is used to implement sharding, replication etc..&lt;/p&gt;

&lt;p&gt;&lt;img src="http://ashutoshraina.github.io/stylesheets/images/posts/sharding.png" alt="Sharding" /&gt;&lt;/p&gt;

&lt;p&gt;End client applications should go through mongos.&lt;/p&gt;

&lt;p&gt;To create a shard connect to mongos&lt;/p&gt;

&lt;p&gt;Then&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sh.addShard("hostname:port")
sh.enableSharding("dbname")
db.ensureIndex(Key pattern for your shard key)
sh.shardCollection("namespaceforyourCollection",shardkey);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Choosing a shard key&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Filed should be involved in most of the queries&lt;/li&gt;
&lt;li&gt;Good cardinality/granularity&lt;/li&gt;
&lt;li&gt;Shard key should not increase monotonically&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://ashutoshraina.github.io/2013/11/mongodb-replication/</guid><link>http://ashutoshraina.github.io/2013/11/mongodb-replication/</link><title>MongoDB-Replication</title><description>&lt;p&gt;&lt;strong&gt;REPLICATION&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Replication helps us achieve availability and fault-tolerance. A replica set is a set of mongo nodes that replicate data amongst each other asynchronously. One of the replica sets is primary while the rest of them will be secondary.
Writes only happen to the primary. If the primary goes down then an election happens and the new primary comes up.
Minimum number of nodes will be 3, since the election requires a majority of the original set.
If there were only 2 sets then the remaining one is not a majority and you would not be able to write.&lt;/p&gt;

&lt;p&gt;</description><pubDate>Sun, 03 Nov 2013 18:30:00 Z</pubDate><a10:updated>2013-11-03T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;&lt;strong&gt;REPLICATION&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Replication helps us achieve availability and fault-tolerance. A replica set is a set of mongo nodes that replicate data amongst each other asynchronously. One of the replica sets is primary while the rest of them will be secondary.
Writes only happen to the primary. If the primary goes down then an election happens and the new primary comes up.
Minimum number of nodes will be 3, since the election requires a majority of the original set.
If there were only 2 sets then the remaining one is not a majority and you would not be able to write.&lt;/p&gt;

&lt;p&gt;&lt;!--excerpt--&gt;
Replica Set Elections&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Regular Node : It has the data and can become primary or secondary.
Arbiter : It is just there for voting purposes. We need it if we want an even number of nodes. It has no data on it.
Delayed/Regular : It can be set to a few hours after the nodes. It cannot become primary. It's priority is set to 0.
Hidden Node : It cannot become a primary node. It's priority is set to 0.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default the reads and writes go to the primary. You can go to secondary for reading. This means that you might read stale data. The lag between nodes is not guaranteed since the process is async. If you read from secondary then what we have is &lt;em&gt;"eventual consistency"&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rs.slaveOk() -- ok to read from the secondary
rs.isMaster() -- checks whether the node is master
rs.status() -- gives the current status of the replica set.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the database locals , the collection oplogs.rs has all the operational logs. Replication happens when secondary nodes query the primary for the changes from a given timestamp. OpLog is the statement based replication log.
Replication happens in a statement driven manner?
e.g If a statement deletes 100 documents on the primary then there will 100 statements that are sent to the secondary to execute. There is no binary replication. This allows us to run different version of mongodb on different machines.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Try to keep the OpLog small on 64 bit machine since it defaults to a large value on 64 bit systems.&lt;/li&gt;
&lt;li&gt;For replica sets don't use localhost or the ip address of the machine.&lt;/li&gt;
&lt;li&gt;Use a logical name, that is the best practice.&lt;/li&gt;
&lt;li&gt;Use DNS.&lt;/li&gt;&lt;/li&gt;
&lt;li&gt;Pick appropriate TTL as well.&lt;/li&gt;
&lt;/ul&gt;
</a10:content></item><item><guid isPermaLink="true">http://ashutoshraina.github.io/2013/10/review-csharp-indepth/</guid><link>http://ashutoshraina.github.io/2013/10/review-csharp-indepth/</link><title>Review-CSharp in Depth.</title><description>&lt;p&gt;I have read the second edition as well. The third edition carries on from there and provides a deeper look in C# 5 and it's key feature async/await. If you want to understand what goes on behind the scenes, this one is for you. Jon Skeet ( yes the famous guy &lt;a href="http://stackoverflow.com/users/22656/jon-skeet" title="Jon Skeet"&gt;Jon Skeet&lt;/a&gt;) has managed to come out with a great book once again.&lt;/p&gt;

</description><pubDate>Tue, 22 Oct 2013 18:30:00 Z</pubDate><a10:updated>2013-10-22T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;I have read the second edition as well. The third edition carries on from there and provides a deeper look in C# 5 and it's key feature async/await. If you want to understand what goes on behind the scenes, this one is for you. Jon Skeet ( yes the famous guy &lt;a href="http://stackoverflow.com/users/22656/jon-skeet" title="Jon Skeet"&gt;Jon Skeet&lt;/a&gt;) has managed to come out with a great book once again.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Jon starts easy on this, but doesn't hold back. The prose is lucid yet well paced. It is one of the few books that make the effort to take the reader on journey. The journey begins with C#1 and then continues to C#5. Hardly any chapters drag on anymore than they should. Linq is covered in great depth and is a nicely written with enough diagrams to visualize what is happening under the hood. Generics is one my personal favourites. The text is nice, so are the code samples. I have never really understood generics completely, but the books does make things a lot clearer. The treatment of dynamic is really nice. It goes into the heart of the DLR and shows everything that you need to know to really understand dynamic. &lt;/p&gt;

&lt;p&gt;The book really shines when you move to &lt;em&gt;async/await&lt;/em&gt;. Jon makes a rather tough concept easier. I had to read it several times but each time the concept became easier. I only wish we moved away from the download the web page example for async. The book does spend time on compiler transformations that are behind &lt;em&gt;async/await&lt;/em&gt;. Be patient when you read it, it will take time to sink in.&lt;/p&gt;

&lt;p&gt;The only part that has been left out from the third edition is the chapter on Code Contracts. Jon clearly mentions that the topic hasn't gained as much traction as he hoped. It may come back in the future though. As many have mentioned this before this is not a book for beginners. Use this to become a better C# programmer, after you have written C# for some time. This is a must have in your collection, especially if you work with C# day in and day out. It will give you a greater understanding of how the language designers wanted you think, and what makes C# a real joy.
A 4.5/5 for this one, keeping the 0.5 for the next edition :).&lt;/p&gt;

&lt;p&gt;P.S. Even the appendix is handy.&lt;/p&gt;

&lt;p&gt;Disclosure : I got a free copy of the book to review.  The review is my own opinion and not influenced by anyone else.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://ashutoshraina.github.io/2013/10/mongodb-understanding-your-queries-through-explainplan/</guid><link>http://ashutoshraina.github.io/2013/10/mongodb-understanding-your-queries-through-explainplan/</link><title>MongoDB-Understanding queries through explain plan</title><description>&lt;p&gt;Understanding the queries we write is very critical and MongoDB does a good job here. Developers will find it easy to understand what the queries are doing and where to look for bottlenecks. Well defined parameters and also well documented ones make life a lot easier.
The details have been taken from the mongodb website and presented here for continuity of series.&lt;/p&gt;

</description><pubDate>Sat, 12 Oct 2013 18:30:00 Z</pubDate><a10:updated>2013-10-12T18:30:00Z</a10:updated><a10:content type="text">&lt;p&gt;Understanding the queries we write is very critical and MongoDB does a good job here. Developers will find it easy to understand what the queries are doing and where to look for bottlenecks. Well defined parameters and also well documented ones make life a lot easier.
The details have been taken from the mongodb website and presented here for continuity of series.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;&lt;strong&gt;Explain Output Fields&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.cursor&lt;/em&gt;
cursor is a string that reports the type of cursor used by the query operation:&lt;/p&gt;

&lt;p&gt;BasicCursor indicates a full collection scan.
BtreeCursor indicates that the query used an index. The cursor includes name of the index. When a query uses an index, the output of explain() includes indexBounds details.
GeoSearchCursor indicates that the query used a geospatial index.
explain.isMultiKey
isMultiKey is a boolean. When true, the query uses a multikey index, where one of the fields in the index holds an array.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.n&lt;/em&gt;
n is a number that reflects the number of documents that match the query selection criteria.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.nscannedObjects&lt;/em&gt;
Specifies the total number of documents scanned during the query. The nscannedObjects may be lower than nscanned, such as if the index covers a query. See indexOnly. Additionally, the nscannedObjects may be lower than nscanned in the case of multikey index on an array field with duplicate documents.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.nscanned&lt;/em&gt;
Specifies the total number of documents or index entries scanned during the database operation. You want n and nscanned to be close in value as possible. The nscanned value may be higher than the nscannedObjects value, such as if the index covers a query. See indexOnly.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.nscannedObjectsAllPlans&lt;/em&gt;
nscannedObjectsAllPlans is a number that reflects the total number of documents scanned for all query plans during the database operation.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.nscannedAllPlans&lt;/em&gt;
nscannedAllPlans is a number that reflects the total number of documents or index entries scanned for all query plans during the database operation.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.scanAndOrder&lt;/em&gt;
scanAndOrder is a boolean that is true when the query cannot use the index for returning sorted results.&lt;/p&gt;

&lt;p&gt;When true, MongoDB must sort the documents after it retrieves them from either an index cursor or a cursor that scans the entire collection.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.indexOnly&lt;/em&gt;
indexOnly is a boolean value that returns true when the query is covered by the index indicated in the cursor field. When an index covers a query, MongoDB can both match the query conditions and return the results using only the index because:&lt;/p&gt;

&lt;p&gt;all the fields in the query are part of that index, and
all the fields returned in the results set are in the same index.
explain.nYields
nYields is a number that reflects the number of times this query yielded the read lock to allow waiting writes execute.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.nChunkSkips&lt;/em&gt;
nChunkSkips is a number that reflects the number of documents skipped because of active chunk migrations in a sharded system. Typically this will be zero. A number greater than zero is ok, but indicates a little bit of inefficiency.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.millis&lt;/em&gt;
millis is a number that reflects the time in milliseconds to complete the query.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.indexBounds&lt;/em&gt;
indexBounds is a document that contains the lower and upper index key bounds. This field resembles one of the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;"indexBounds" : {
"start" : {  : , ...  },
"end" : {  : , ... }
},
"indexBounds" : { "" : [ [ ,  ] ],
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;explain.allPlans&lt;/em&gt;
allPlans is an array that holds the list of plans the query optimizer runs in order to select the index for the query. Displays only when the  parameter to explain() is true or 1.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.oldPlan&lt;/em&gt;
oldPlan is a document value that contains the previous plan selected by the query optimizer for the query. Displays only when the  parameter to explain() is true or 1.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.server&lt;/em&gt;
server is a string that reports the MongoDB server.&lt;/p&gt;

&lt;p&gt;$or Query Output Fields
explain.clauses
clauses is an array that holds the Core Explain Output Fields information for each clause of the $or expression. clauses is only included when the clauses in the $or expression use indexes.&lt;/p&gt;

&lt;p&gt;Sharded Collections Output Fields
&lt;em&gt;explain.clusteredType&lt;/em&gt;
clusteredType is a string that reports the access pattern for shards. The value is:&lt;/p&gt;

&lt;p&gt;ParallelSort, if the mongos queries shards in parallel.
SerialServer, if the mongos queries shards sequentially.
&lt;em&gt;explain.shards&lt;/em&gt;
shards contains fields for each shard in the cluster accessed during the query. Each field holds the Core Explain Output Fields for that shard.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.millisShardTotal&lt;/em&gt;
millisShardTotal is a number that reports the total time in milliseconds for the query to run on the shards.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.millisShardAvg&lt;/em&gt;
millisShardAvg is a number that reports the average time in millisecond for the query to run on each shard.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.numQueries&lt;/em&gt;
numQueries is a number that reports the total number of queries executed.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;explain.numShards&lt;/em&gt;
numShards is a number that reports the total number of shards queried.&lt;/p&gt;

&lt;p&gt;Lastly, some more profiling tips that can be pretty useful.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Logging Slow Queries&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There are 3 levels for the profiler 0 OFF , 1Slow, 2 ALL&lt;/li&gt;
&lt;li&gt;Enable this using mongod -profile 1 --slowms 2&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Db.getProfilingLevel()&lt;/code&gt; to get the current profiling level.&lt;/li&gt;
&lt;li&gt;If you want to get all queries that took longer than 3 second, ordered by timestamp descending&lt;/li&gt;
&lt;li&gt;&lt;code&gt;db.system.profile.find({millis:{$gt:3000}}).sort({ts:-1})&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Mongotop can be run set to a specific time interval to determine where is the majority of the time spent. This utility tracks the time that mongod spends on reads and writes. The information is on a per collection basis.
I prefer to increase the time for reporting from the default 1 sec to somewhere close to 5 sec or more (this is just a random number that I feel comfortable with..otherwise the data is to verbose to make any sense).&lt;/p&gt;

&lt;p&gt;This should be a good start. We will go into some more concepts about monitoring mongodb before going into sharding etc..&lt;/p&gt;
</a10:content></item></channel></rss>